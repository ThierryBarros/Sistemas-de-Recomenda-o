{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from collections import defaultdict\n",
    "from surprise import get_dataset_dir\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "data = Dataset.load_builtin('ml-100k')\n",
    "trainset = data.build_full_trainset()\n",
    "algo = KNNBasic()\n",
    "algo.fit(trainset)\n",
    "\n",
    "testset = trainset.build_anti_testset()\n",
    "\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9778  0.9801  0.9716  0.9889  0.9743  0.9785  0.0059  \n",
      "Fit time          0.33    0.34    0.33    0.33    0.33    0.33    0.01    \n",
      "Test time         3.00    2.92    2.95    2.90    2.94    2.94    0.03    \n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    \n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "\n",
    "top_n = get_top_n(predictions, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Prefontaine (1997)\n",
      "Santa with Muscles (1996)\n",
      "Great Day in Harlem, A (1994)\n",
      "Aiqing wansui (1994)\n",
      "Star Kid (1997)\n"
     ]
    }
   ],
   "source": [
    "def read_item_names():\n",
    "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
    "    rid_to_name = {}\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_name[line[0]] = line[1]\n",
    "\n",
    "    return rid_to_name\n",
    "\n",
    "rid_to_name= read_item_names()\n",
    "\n",
    "user_id = int(raw_input())\n",
    "\n",
    "user = algo.trainset.to_inner_uid(unicode(user_id))\n",
    "\n",
    "\n",
    "for i in top_n.get(unicode(user)):\n",
    "    print rid_to_name[i[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is id: 10 Age: 53 Gender: M Occupation: lawyer\n",
      "\n",
      "The 3 nearest neighbors\n",
      "id 146 Age: 45 Gender: M Occupation: artist\n",
      "id 285 Age: 25 Gender: M Occupation: programmer\n",
      "id 363 Age: 20 Gender: M Occupation: student\n"
     ]
    }
   ],
   "source": [
    "user_id_neighbors = algo.get_neighbors(user, k=3)\n",
    "\n",
    "def read_user_info():\n",
    "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.user'\n",
    "    rid_to_name = {}\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_name[line[0]] = (line[1],line[2],line[3])\n",
    "\n",
    "    return rid_to_name\n",
    "\n",
    "rid_to_name = read_user_info()\n",
    "print 'The user is','id:',user_id,'Age:',rid_to_name[unicode(user_id)][0],'Gender:',rid_to_name[unicode(user_id)][1],'Occupation:',rid_to_name[unicode(user_id)][2]\n",
    "\n",
    "print \n",
    "\n",
    "print('The 3 nearest neighbors')\n",
    "for i in user_id_neighbors:\n",
    "    print 'id',i,'Age:',rid_to_name[unicode(i)][0],'Gender:',rid_to_name[unicode(i)][1],'Occupation:',rid_to_name[unicode(i)][2]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
