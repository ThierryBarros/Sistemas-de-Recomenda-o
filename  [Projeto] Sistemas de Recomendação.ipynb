{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from collections import defaultdict\n",
    "from surprise import get_dataset_dir\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "data = Dataset.load_builtin('ml-100k')\n",
    "trainset = data.build_full_trainset()\n",
    "algo = KNNBasic()\n",
    "algo.fit(trainset)\n",
    "\n",
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9784  0.9841  0.9763  0.9820  0.9730  0.9787  0.0040  \n",
      "Fit time          0.36    0.32    0.35    0.35    0.37    0.35    0.02    \n",
      "Test time         2.92    2.91    2.95    3.19    3.03    3.00    0.10    \n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named sklearn.metrics",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4ca0231d5f48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named sklearn.metrics"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "mse = mean_squared_error(trainset, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    \n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "\n",
    "top_n = get_top_n(predictions, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Delta of Venus (1994)\n",
      "Santa with Muscles (1996)\n",
      "Aiqing wansui (1994)\n",
      "Star Kid (1997)\n",
      "Someone Else's America (1995)\n"
     ]
    }
   ],
   "source": [
    "def read_item_names():\n",
    "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
    "    rid_to_name = {}\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_name[line[0]] = line[1]\n",
    "\n",
    "    return rid_to_name\n",
    "\n",
    "rid_to_name= read_item_names()\n",
    "\n",
    "user_id = int(raw_input())\n",
    "\n",
    "user = algo.trainset.to_inner_uid(unicode(user_id))\n",
    "\n",
    "\n",
    "for i in top_n.get(unicode(user)):\n",
    "    print rid_to_name[i[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is id: 10 Age: 53 Gender: M Occupation: lawyer\n",
      "\n",
      "The 3 nearest neighbors\n",
      "id 133 Age: 53 Gender: M Occupation: engineer\n",
      "id 311 Age: 32 Gender: M Occupation: technician\n",
      "id 345 Age: 28 Gender: F Occupation: librarian\n"
     ]
    }
   ],
   "source": [
    "user_id_neighbors = algo.get_neighbors(user, k=3)\n",
    "\n",
    "def read_user_info():\n",
    "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.user'\n",
    "    rid_to_name = {}\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_name[line[0]] = (line[1],line[2],line[3])\n",
    "\n",
    "    return rid_to_name\n",
    "\n",
    "rid_to_name = read_user_info()\n",
    "print 'The user is','id:',user_id,'Age:',rid_to_name[unicode(user_id)][0],'Gender:',rid_to_name[unicode(user_id)][1],'Occupation:',rid_to_name[unicode(user_id)][2]\n",
    "\n",
    "print \n",
    "\n",
    "print('The 3 nearest neighbors')\n",
    "for i in user_id_neighbors:\n",
    "    print 'id',i,'Age:',rid_to_name[unicode(i)][0],'Gender:',rid_to_name[unicode(i)][1],'Occupation:',rid_to_name[unicode(i)][2]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
